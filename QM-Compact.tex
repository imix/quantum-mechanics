\documentclass[10pt,a4paper]{book}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{braket}
\usepackage{dsfont}
\usepackage{hyperref}

\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    filecolor=magenta,      
    urlcolor=cyan,
    pdftitle={Quantum mechanics},
    pdfpagemode=FullScreen,
    }


\title{Quantum Mechanics}
\author{Stefan Aeschbacher}
\date{\today}

\newtheorem{post}{Postulate}

\DeclareMathOperator {\op1} {\mathds{1}}
\DeclareMathOperator {\opH} {\hat{H}}
\DeclareMathOperator {\opA} {\hat{A}}
\DeclareMathOperator {\opB} {\hat{B}}
\DeclareMathOperator {\opC} {\hat{C}}
\DeclareMathOperator {\opU} {\hat{U}}
\DeclareMathOperator {\opV} {\hat{V}}
\DeclareMathOperator {\opPos} {\hat{x}}
\DeclareMathOperator {\opMom} {\hat{p}}
\DeclareMathOperator {\opSigma} {\hat{\sigma}}

\begin{document}

\maketitle
\tableofcontents

\chapter{Dirac notation}
A bra $\bra{v}$ is an element in a complex vector space. The corresponding ket $\ket{v}$ is an elemen in its dual space.
The usual rules of linear algebra are valid:
\begin{align}
	\ket{u} + \ket{v} & = \ket{w} \\
	c\ket{v} &= \ket{u}; c \in \mathbb{C}
\end{align}

Convert between bras and kets:
\begin{align}
	c_1 \ket{v_1} + c_2 \ket{v_2} \iff c_1^* \bra{v_1} + c_2^* \bra{v_2}
\end{align}

\section{Inner product}
\begin{align}
	\braket{u|v} & = \braket{v|u}^* \\
	\braket{v|v} & \ge 0 \\
	\braket{v|v} &= 0 \iff v = 0
\end{align}
Linearity in the second argument and antilinear in the first:
\begin{align}
	\braket{u|c_1 v_1 + c_2 v_2} & = c_1\braket{u|v_1} + c_2\braket{u|v_2} \\
	\braket{c_1 u_1 + c_2 u_2|v} & = c_1^*\braket{u_1|v} + c_2^*\braket{u_2|v} \\
\end{align}

For $v, u \in \mathbb{C}^n$ as vectors ($\bra{v}$ is a row vector, $\ket{u}$ is a column vector)
\begin{align}
	\braket{v|u} = \sum_{n}v_i^*u_i
\end{align}

For functions $f, g \in \mathbb{C}$ as vectors with $x \in [0,L]$
\begin{align}
	\braket{f|g} = \int_0^Lf^*(x)g(x)dx
\end{align}

For a set of basis vectors $\{e_i\}$ (kronecker delta)
\begin{align}
	\braket{e_i|e_j} = \delta_{ij}
\end{align}

Write a vector as a linear combination of basis vectors
\begin{align}
	\ket{v} = \sum_{i=0}^n v_i\ket{e_i} &= \sum_{i=0}^n \ket{e_i}\bra{e_i}\ket{v} \\
	\braket{e_i|v} &= v_i
\end{align}

\section{Outer product}
A bra and a ket can be combined in the outer product to create an operator
\textbf{\begin{align}
	X &= \ket{v}\bra{u} \\
	X\ket{\Psi} &= \ket{v}\bra{u}\ket{\Psi} = \ket{v}\braket{u|\Psi}  \\
\end{align}
}

\chapter{Postulates}
\section{Postulate 1: state}

\begin{post}
	The state of a physical system is described by a state vector that belongs to a complex vector space V, called the state space of the system.
\end{post}


\section{Postulate X: time evolution}
\begin{align}
	i\hbar \frac{ \partial } { \partial t } \ket{ \Psi(t) } = \opH(t)\ket{ \Psi(t) }
\end{align}


\chapter{State space}
\begin{align}
	\ket{ \Psi_1} + \ket{ \Psi_2} & = \ket{ \Psi_3}                 \\
	\ket{ \Psi_1} + \ket{ \Psi_2} & = \ket{ \Psi_2} + \ket{ \Psi_1}
\end{align}
\chapter{Operators}
\section{Basic Properties}
An operator acting on a ket creates a new ket:
\begin{align}
	\opA \ket{\Psi} = \ket{\Psi'} \\
	\ket{\Psi}, \ket{\Psi'} \in V
\end{align}
Operators are linear
\begin{align}
	\opA (a_1\ket{\Psi_1} + a_2\ket{\Psi_2}) = (a_1\opA\ket{\Psi_1} + a_2\opA\ket{\Psi_2}) \\
	\ket{\Psi}, \ket{\Psi'} \in V; a_1, a_2 \in \mathbb{C}
\end{align}
Operators are associative and commutative under addition
\begin{align}
	\opA + (\opB + \opC) = (\opA + \opB) + \opC \\
	\opA + \opB = \opB + \opA
\end{align}
Multiplying operators is interpreted as applying them to kets. It is associative but NOT (in general) commutative.
\begin{align}
	\opA\opB\ket{\Psi} = \opA(\opB\ket{\Psi}) = \opA\ket{\Psi'} \\
	\opA(\opB\opC) = (\opA\opB)\opC                             \\
	\opA\opB \ne \opB\opA
\end{align}
The lack of commutativeness makes the "commutator" useful
\begin{align}
	[\opA, \opB] = \opA\opB - \opB\opA \\
\end{align}
The inverse $\opA^{-1}$ of an operator is defined by
\begin{align}\label{InverseOperator}
	\opA^{-1}\opA = \opA\opA^{-1} = \op1
\end{align}
    \section{Hermitian Operators}
    An operator is called Hermitian (or self-adjoint) if it is it's own hermitian conjugate $\opA = \opA^\dagger$

\begin{align}
	\opA\ket{A} = \ket{B} \rightarrow \bra{A}\opA^\dagger = \bra{B} \\
	\opA\ket{A} = \ket{B} \rightarrow \bra{A}\opA = \bra{B}         \\
\end{align}

A hermitian operator $\opA$ has the following properties
\begin{enumerate}
	\item $\opA\ket{\lambda} = \lambda \ket{\lambda} \rightarrow \lambda \in \mathbb{R}$
	\item $\braket{\opA} = \bra{\Psi}\opA\ket{\Psi} \in \mathbb{R}$
	\item All eigenvectors with different eigenvalues are orthogonal
\end{enumerate}

\section{Projection Operators}
A projection operator is defined
\begin{align}
\end{align}

\section{Unitary operators}
A unitary operator is defined by
\begin{align}
	\opU^{-1} = \opU^\dagger
\end{align}
This leads to (see also \eqref{InverseOperator})
\begin{align}
	\opU^\dagger\opU = \opU\opU^\dagger = \op1
\end{align}
The product of two unitary operators ($\opU^{-1} = \opU^\dagger; \opV^{-1} = \opV^\dagger$) is as well unitary
\begin{align}
	(\opU\opV)^\dagger(\opU\opV) = \op1 \\
	(\opU\opV)(\opU\opV)^\dagger = \op1
\end{align}
The eigenvalues of a unitary operator have magnitude 1
\begin{align}
	\opU\ket{\lambda} = \lambda\ket{\lambda} \Rightarrow |\lambda|^2 = 1 \\
	|\lambda\| = 1 \Rightarrow \lambda = e^{i\phi_\lambda}; \phi_\lambda \in \mathbb{R}
\end{align}
The eigenvectors are orthogonal $\braket{\mu|\lambda} = 0$. 

Unitary transformations conserve the scalar product of two kets and the norm of a ket.
\begin{align}
	\ket{\Psi_1'} = \opU \ket{\Psi_1'}&; \ket{\Psi_2'} = \opU \ket{\Psi_2'} \\
	\braket{\Psi_1'|\Psi_2'} = \bra{\Psi_1}\opU^\dagger&\opU\ket{\Psi_1} =\braket{\Psi_1|\Psi_2} \\
	\braket{\Psi_1'|\Psi_1'} &=\braket{\Psi_1|\Psi_1} \\
\end{align}

See also: \href{https://www.youtube.com/watch?v=baIT6HaaYuQ}{Prof.M. Unitary Operators} and \href{https://www.youtube.com/watch?v=tRWBoossG0Y&list=PL701CD168D02FF56F&index=9}{TM Lecture 4}

\chapter{Eigenvectors and Eigenvalues}
\section{Degenerate Eigenvectors}
If two eigenvectors have the same eigenvalue:
\begin{align}
	\opH\ket{\lambda_1} = \lambda \ket{\lambda_1} \\
	\opH\ket{\lambda_2} = \lambda \ket{\lambda_2}
\end{align}
their linear combination is an eigenvector as well:
\begin{align}
	\alpha \opH\ket{\lambda_1} = \lambda \alpha \ket{\lambda_1} \\
	\beta \opH\ket{\lambda_1} = \lambda \beta \ket{\lambda_1}   \\
	\opH[\alpha \ket{\lambda_1} + \beta \ket{\lambda_2}] = \lambda [\alpha \ket{\lambda_1} + \beta \ket{\lambda_2}]
\end{align}
Therefore it is possible to create two orthogonal eigenvectors for this eigenvalue.

The probability in the degenerate case is the sum of the probabilities for each eigenvector $| \bra{\opH} \ket{\lambda_1}|^2 + | \bra{\opH} \ket{\lambda_2}|^2$

\chapter{Uncertanity}
\section{Probabilities}
When $\Psi$ is represented in a basis $u$
\begin{align}
	\opA\ket{u_n} = \lambda_n\ket{u_n}\\
	\ket{\Psi} = \sum_{n}c_n\ket{u_n} \\
	c_n = \braket{u_n|\Psi}
\end{align}
$|c_n|^2$ is the probability to get the eigenvalue $\lambda_n$ as a result.
\section{Expectation value and RMS}
Expectation value of $\opA$ in state $\Psi$
\begin{align}
	\braket{\opA}_\Psi = \bra{\Psi}\opA\ket{\Psi}
\end{align}
Root mean square deviation
\begin{align}
	\Delta \opA &= \sqrt{\braket{\opSigma_A^2}_\Psi}\\
	\opSigma_A &= \opA - \braket{\opA}_\Psi \\
	\Delta \opA &= \sqrt{\braket{\opA^2}_\Psi - \braket{\opA}_\Psi^2}
\end{align}
\section{Uncertanity Principle}
\begin{align}
	\Delta\opA\Delta\opB \geq \frac{1}{2}|\braket{[\opA\opB]}|
\end{align}
\section{Position and Momentun}
\begin{align}
	[\opPos,\opMom] &= i\hbar \\
	\Delta\opPos\Delta\opMom &\geq \frac{\hbar}{2}
\end{align}
\end{document}
